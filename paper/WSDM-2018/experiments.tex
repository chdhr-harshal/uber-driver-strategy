%!TEX root = main.tex

\section{Experiments: Optimal Uber driver strategy}
\label{sec:experiments}

We consider the problem of evaluating optimal in expectation strategies for drivers using the on-demand ride service -- Uber. The driver strategies on this platform must be estimated from past data. This makes it a particularly attractive application for evaluating our framework.

\subsection{\textsc{Data}}
\label{sec:data}
\todo[Harshal]{Fill in data gathering and how we used NYC taxi dataset to create representative Uber data}

\subsection{\textsc{EmpiricalTransitionMatrix}}

The data gathered in the previous section gives us an empirical transition matrix {\matr{M}}, each of its entries $m(i,j)$ denotes the fraction of passenger in zone $i$ travelling to zone $j$. As a result, all the diagonal entries of {\matr{M}} are zeros. However, the \textsc{EmpiricalTransitionMatrix}, {\empiricaltransitionmatrix}, described in Section \ref{sec:problem_setup} assumed that the diagonal entries $f(i,i)$ denote the probabilities of a driver not finding a passenger in zone $i$ in one time unit. Hence, we modify the {\matr{M}} to make it compliant with those assumptions.

\subsubsection{\sc{Modeling successful passenger pickup}}

We use {\passengerarrivalrate} and {\driverarrivalrate} to denote the Poisson arrival rates of passengers and drivers at time $t$, within a zone $i$. Correspondingly, $N(\passengerarrivalrate)$ and $N(\driverarrivalrate)$ denote the number of passenger and driver arrivals in zone $i$ in one time unit. Assuming that passenger and driver arrivals are independent Poisson processes, the random variable $K = N(\passengerarrivalrate) - N(\driverarrivalrate)$ follows \textit{Skellam Distribution} as follows,
\begin{equation}
\Pr[K=k] = e^{-(\passengerarrivalrate + \driverarrivalrate)} \bigg(\frac{\passengerarrivalrate}{\driverarrivalrate}\bigg) I_k\big(2 \sqrt{\passengerarrivalrate \driverarrivalrate}\big)
\end{equation}
where $I_k(z)$ is the modified Bessel function of the first kind. We can depict the random variable $K$ as states of a {\markovchain} in Figure \ref{fig:skellam_markov_chain}.

\note[Harshal]{Although, for simplicity, we assume the independence of the passenger and driver arrival processes, we can also accomodate correlated processes with slight modification.}

\begin{figure}
\begin{center}
\begin{tikzpicture}[->, >=stealth', auto, semithick, node distance=2cm]
\tikzstyle{every state}=[fill=white,draw=black,thick,text=black,scale=0.65]
\node[state]    (-inf)               {$\bf ...$};
\node[state]    (-2)[right of=-inf]   {$\bf -2$};
\node[state]    (-1)[right of=-2]   {$\bf -1$};
\node[state]    (0)[right of=-1]   {$\bf 0$};
\node[state]    (+1)[right of=0]   {$\bf 1$};
\node[state]    (+2)[right of=+1]   {$\bf 2$};
\node[state]    (+inf) [right of=+2] {$\bf ...$};
\path
(-inf)  edge[bend left]         node{$\passengerarrivalrate$}   (-2)
(-2)    edge[bend left]         node{$\passengerarrivalrate$}   (-1)
        edge[bend left,below]   node{$\driverarrivalrate$}       (-inf)
(-1)    edge[bend left]         node{$\passengerarrivalrate$}   (0)
        edge[bend left,below]   node{$\driverarrivalrate$}       (-2)
(0)     edge[bend left]         node{$\passengerarrivalrate$}   (+1)
        edge[bend left,below]   node{$\driverarrivalrate$}       (-1)
(+1)    edge[bend left]         node{$\passengerarrivalrate$}   (+2)
        edge[bend left,below]   node{$\driverarrivalrate$}       (0)
(+2)     edge[bend left]        node{$\passengerarrivalrate$}   (+inf)
        edge[bend left,below]   node{$\driverarrivalrate$}       (+1)
(+inf)  edge[bend left,below]   node{$\driverarrivalrate$}       (+2);
\end{tikzpicture}
\caption{Markov Chain depiction of Skellam Distribution}
\label{fig:skellam_markov_chain}
\end{center}
\end{figure}

Whenever the {\markovchain} is in a non-positive state, there are more drivers than passengers in a given zone. We assume the worst case scenario in which our driver of interest is at the last spot of a FIFO queue. Hence, for a state $k \leq 0$, the driver has to wait for $(|k| + 1)$ passenger arrivals in a unit time for a successful passenger pickup. The probability of a successful passenger pickup can be expressed as,
\begin{equation}
\Pr[N(\passengerarrivalrate) = |k| + 1] = \frac{\passengerarrivalrate^{\big(|k|+1\big)} e^{-\passengerarrivalrate}}{\big(|k| + 1\big)!}
\end{equation}
Thus, we can express a diagonal entry $f(i,i)$ of empirical transition matrix as follows,
\begin{equation}
f(i,i) = 1 - \sum_{k \leq 0} \Pr[K = k] \times \Pr[N(\passengerarrivalrate) \geq |k| + 1]
\end{equation}
To maintain the right stochasticity of {\empiricaltransitionmatrix}, every other entry $f(i,j)$ is calculated as,
\begin{equation}
f(i,j) = (1 - f(i,i)) \times m(i,j)
\end{equation}
The matrix {\empiricaltransitionmatrix}, built in this manner satisfies all our assumptions and can be used in the evaluation of strategies described in previous sections.

% \subsection{\textsc{RewardsMatrix}}

% The data gathered in the previous section gives us a matrix of driver earnings, \matr{E}, from passengers while traveling between any two zones in the city. We also get a costs matrix, \matr{C}, whose each entry, $c(i,j) \leq 0$, denotes the sundry expenses of traveling from zone $i$ to zone $j$, dependent on distance and traffic at the given time. The travel costs can result in negative net rewards in the {\gohome} and {\relocate} actions, violating the assumption from Section \ref{sec:problem_setup} that $r(i,j) \geq 0$. In this section, we describe the construction of \textsc{RewardsMatrix}, {\rewardsmatrix}, corresponding to each driver action compliant with our assumptions.

% \subsubsection{\textsc{Modifying the CostsMatrix}}
% If $min\_cost$ is the minimum entry in the matrix \matr{C}, each entry of the modified costs matrix, \matr{C'} is calculated as,
% \begin{equation}
% c'(i,j) = c(i,j) - min\_cost
% \end{equation}
% As a result of the above modification, $\forall i,j : c'(i,j) \geq 0$.

% \subsubsection{\textsc{RewardsMatrix}}
% In order to be compliant with the assumption in Section \ref{sec:problem_setup}, we define two kinds of \textsc{RewardsMatrix}, one for the action {\getpassenger} and another for the actions {\gohome} and {\relocate}.

% \begin{itemize}
% 	\item For the {\getpassenger} action, we define the rewards matrix as,
% 	\begin{equation}
% 		r(i,j) = e(i,j) + c'(i,j) 
% 	\end{equation}
% 	\item For the {\gohome} and {\relocate} actions, the rewards matrix is same as the modified costs matrix.
% 	\begin{equation}
% 		r(i,j) = c'(i,j)
% 	\end{equation}
% \end{itemize}
% In both cases, we set the diagonal entries of the matrix to zero i.e., $\forall i: r(i,i) = 0$.

% It should be noted that this modification does not affect the optimal action choice in any strategy. It merely ensures that the input vectors to the Bisection Algorithm from Section \ref{sec:sensitivity} are always non-negative vectors. Furthermore, while calculating the actual {\totalexpectedearnings} of a driver, we can backtrack these modifications.

% \subsection{\textsc{Comparing robust and nominal strategies}}
% In this section, we compare various strategies. When we choose, $\beta = \betamax$, there is no uncertainty, and we get solution computed via the classical Bellman recursion; referred to as nominal strategy. The robust strategy corresponds to solving the MDP with varying values of $\beta$.

% \subsection{\textsc{Effect of Inaccuracy is uncertainty level}}
% The previous section assumes that, in the robust case, we are able to estimate exactly the precise value of the uncertainty level. In practice, the parameter $\beta$ also has to be estimated. In this section, we study the sensitivity of the robust approach with respect to inaccuracies in the uncertainty parameter $\beta$.