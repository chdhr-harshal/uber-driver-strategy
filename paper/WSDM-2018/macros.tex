%!TEX root = main.tex

% notations
\renewcommand{\vec}[1]{\ensuremath{\mathbf{#1}}} % vector
\newcommand{\matr}[1]{\ensuremath{\mathbf{#1}}} % matrix
\newcommand{\transpose}[1]{\ensuremath{\mathbf{#1}^\intercal}} % transpose

% Dot product notation
\makeatletter
\newcommand*\bigcdot{\mathpalette\bigcdot@{.5}}
\newcommand*\bigcdot@[2]{\mathbin{\vcenter{\hbox{\scalebox{#2}{$\m@th#1\bullet$}}}}}
\makeatother

% special terms
\newcommand{\markovchain}{{\it Markov Chain}}
\newcommand{\mdp}{{\it Markov Decision Process}}
\newcommand{\totalexpectedearnings}{{\it total expected earnings}}
\newcommand{\nominalproblem}{{\it nominal problem}}
\newcommand{\robustcontrolproblem}{{\it robust control problem}}
\newcommand{\epsilonsuboptimal}{\ensuremath{\epsilon}-\textit{suboptimal policy}}

%problems
\newcommand{\originalproblem}{{\textsc{MaxEarnings}}}
\newcommand{\robustproblem}{{\textsc{RobustEarnings}}}

% strategies
\newcommand{\naive}{{\textsc{Naive Strategy}}}
\newcommand{\relocation}{{\textsc{Relocation Strategy}}}
\newcommand{\flexible}{{\textsc{Flexible Schedule Strategy}}}
\newcommand{\relocationflexible}{{\textsc{Relocation with Flexible Schedule Strategy}}}
\newcommand{\earningsgoal}{{\textsc{Fixed Earnings Goal Strategy}}}

% actions
\newcommand{\getpassenger}{{\it Get Passenger}}
\newcommand{\gohome}{{\it Go Home}}
\newcommand{\relocate}{{\it Relocate}}

% symbols
\newcommand{\cityzones}{\ensuremath{\mathcal{X}}}
\newcommand{\countmatrix}{{\matr{C}}}
\newcommand{\rowcountmatrix}{{\mathbf{c}}}
\newcommand{\empiricaltransitionmatrix}{{\matr{F}}}
\newcommand{\truetransitionmatrix}{{\matr{P}}}
\newcommand{\rowtruetransitionmatrix}{{\mathbf{p}}}
\newcommand{\traveltimematrix}{{\matr{T}}}
\newcommand{\rewardsmatrix}{{\matr{R}}}
\newcommand{\homezone}{{\ensuremath{i_0}}}
\newcommand{\actionsset}{\ensuremath{\mathcal{A}}}
\newcommand{\policy}{\ensuremath{\pi}}
\newcommand{\policyspace}{\ensuremath{\Pi}}
\newcommand{\getpassengeraction}{\ensuremath{a_0}}
\newcommand{\gohomeaction}{\ensuremath{a_1}}
\newcommand{\relocateaction}{\ensuremath{a_2(j)}}
\newcommand{\actualaction}{\ensuremath{\hat{a}}}
\newcommand{\actuallocation}{\ensuremath{\hat{i}}}
\newcommand{\actualtime}{\ensuremath{\hat{t}}}
\newcommand{\earnings}{\ensuremath{\mathcal{E}}}
\newcommand{\betamax}{\ensuremath{\beta_{\textrm{max}}}}
\newcommand{\likelihoodregion}{\ensuremath{\mathcal{P}}}
\newcommand{\vmin}{\ensuremath{v_{\textrm{min}}}}
\newcommand{\vmax}{\ensuremath{v_{\textrm{max}}}}
\newcommand{\epsilonsuboptimalpolicy}{\ensuremath{{\pi}^{\epsilon}}}
\newcommand{\passengerarrivalrate}{\ensuremath{\lambda}}
\newcommand{\driverarrivalrate}{\ensuremath{\mu}}


% For action reward #1 is subscript (zone) #2 is superscript (time) #3 is action.
\newcommand{\actionearning}[3]{\ensuremath{E({#1},{#2},{#3})}}
\newcommand{\cumulativeearning}[2]{\ensuremath{v_{#1}^{#2}}}
\newcommand{\inducedearningvector}[3]{\ensuremath{\mathbf{v}_{#1}^{#2}({#3})}}


\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\newcommand{\etal}{\emph{et al.}}

%formating
\newcommand{\spara}[1]{\smallskip\noindent{\bf{#1}}}
\newcommand{\mpara}[1]{\medskip\noindent{\bf{#1}}}
\newcommand{\bpara}[1]{\bigskip\noindent{\bf{#1}}}

\newcommand{\squishlist}{\begin{list}{$\bullet$}
  { \setlength{\itemsep}{0pt}
     \setlength{\parsep}{3pt}
     \setlength{\topsep}{3pt}
     \setlength{\partopsep}{0pt}
     \setlength{\leftmargin}{1.5em}
     \setlength{\labelwidth}{1em}
     \setlength{\labelsep}{0.5em} } }
\newcommand{\squishend}{
  \end{list}  }
  
  \newtheorem{problem}{Problem}

